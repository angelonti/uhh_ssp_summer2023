{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "frame_length = 32\n",
    "frame_shift = 16"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "speech1 = sf.read('resources/speech1.wav')\n",
    "phone = sf.read('resources/phone.wav')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "(45466,)"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech1[0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "(32000,)"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone[0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling rate of speech 1 is 16000\n",
      "sampling rate of phone is 16000\n"
     ]
    }
   ],
   "source": [
    "print(f'sampling rate of speech 1 is {speech1[1]}')\n",
    "print(f'sampling rate of phone is {phone[1]}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "sampling_rate = speech1[1]\n",
    "nyquist_frequency = sampling_rate/2\n",
    "speech1_data = speech1[0]\n",
    "phone_data = phone[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "def my_windowing(v_signal: np.ndarray, sampling_rate: int, frame_length: int, frame_shift: int) -> [np.ndarray, np.ndarray]:\n",
    "    millis_per_point = 1000 / sampling_rate\n",
    "    frame_length_num_points = frame_length / millis_per_point\n",
    "    frame_shift_num_points = frame_shift / millis_per_point\n",
    "    num_frames = int(np.floor((len(v_signal) - frame_length_num_points) / frame_shift_num_points) + 1)\n",
    "    m_frames = np.zeros((num_frames, int(frame_length_num_points)))\n",
    "    v_time_frame = np.zeros(num_frames)\n",
    "    for i in range(num_frames):\n",
    "        start = int(i * frame_shift_num_points)\n",
    "        end = int(i * frame_shift_num_points + frame_length_num_points)\n",
    "        m_frames[i] = v_signal[start:end]\n",
    "        v_time_frame[i] = (start + end)/(2*sampling_rate)\n",
    "    return [m_frames, v_time_frame]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "def compute_stft(v_signal: np.ndarray, fs: int, frame_length: int, frame_shift: int, v_analysis_window: np.ndarray) -> [np.ndarray, np.ndarray, np.ndarray]:\n",
    "    m_frames, v_time_frame = my_windowing(v_signal, fs, frame_length, frame_shift)\n",
    "    m_stft_full = np.zeros(m_frames.shape, dtype=np.complex128)\n",
    "    v_analysis_window = v_analysis_window(m_frames.shape[1])\n",
    "    for i in range(m_frames.shape[0]):\n",
    "        m_stft_full[i] = np.fft.fft(m_frames[i]*v_analysis_window)\n",
    "    v_freq = np.fft.rfftfreq(m_stft_full.shape[1], 1/fs)\n",
    "    #v_freq = v_freq[:int(v_freq.shape[0]/2)+1]\n",
    "    m_stft = remove_upper_half_spectrum(m_stft_full)\n",
    "    return [m_stft, v_freq, v_time_frame]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "def remove_upper_half_spectrum(m_stft: np.ndarray) -> np.ndarray:\n",
    "    m_stft_new = m_stft[:, :(int(m_stft.shape[1]/2)+1)]\n",
    "    return m_stft_new"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_freq_axis(m_mstft_full, num_samples: int):\n",
    "    freq = i_max * sampling_rate / num_samples\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "m_stft, v_freq, v_time_frame = compute_stft(speech1_data, sampling_rate, frame_length, frame_shift, np.hanning)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "data": {
      "text/plain": "array([   0.  ,   31.25,   62.5 ,   93.75,  125.  ,  156.25,  187.5 ,\n        218.75,  250.  ,  281.25,  312.5 ,  343.75,  375.  ,  406.25,\n        437.5 ,  468.75,  500.  ,  531.25,  562.5 ,  593.75,  625.  ,\n        656.25,  687.5 ,  718.75,  750.  ,  781.25,  812.5 ,  843.75,\n        875.  ,  906.25,  937.5 ,  968.75, 1000.  , 1031.25, 1062.5 ,\n       1093.75, 1125.  , 1156.25, 1187.5 , 1218.75, 1250.  , 1281.25,\n       1312.5 , 1343.75, 1375.  , 1406.25, 1437.5 , 1468.75, 1500.  ,\n       1531.25, 1562.5 , 1593.75, 1625.  , 1656.25, 1687.5 , 1718.75,\n       1750.  , 1781.25, 1812.5 , 1843.75, 1875.  , 1906.25, 1937.5 ,\n       1968.75, 2000.  , 2031.25, 2062.5 , 2093.75, 2125.  , 2156.25,\n       2187.5 , 2218.75, 2250.  , 2281.25, 2312.5 , 2343.75, 2375.  ,\n       2406.25, 2437.5 , 2468.75, 2500.  , 2531.25, 2562.5 , 2593.75,\n       2625.  , 2656.25, 2687.5 , 2718.75, 2750.  , 2781.25, 2812.5 ,\n       2843.75, 2875.  , 2906.25, 2937.5 , 2968.75, 3000.  , 3031.25,\n       3062.5 , 3093.75, 3125.  , 3156.25, 3187.5 , 3218.75, 3250.  ,\n       3281.25, 3312.5 , 3343.75, 3375.  , 3406.25, 3437.5 , 3468.75,\n       3500.  , 3531.25, 3562.5 , 3593.75, 3625.  , 3656.25, 3687.5 ,\n       3718.75, 3750.  , 3781.25, 3812.5 , 3843.75, 3875.  , 3906.25,\n       3937.5 , 3968.75, 4000.  , 4031.25, 4062.5 , 4093.75, 4125.  ,\n       4156.25, 4187.5 , 4218.75, 4250.  , 4281.25, 4312.5 , 4343.75,\n       4375.  , 4406.25, 4437.5 , 4468.75, 4500.  , 4531.25, 4562.5 ,\n       4593.75, 4625.  , 4656.25, 4687.5 , 4718.75, 4750.  , 4781.25,\n       4812.5 , 4843.75, 4875.  , 4906.25, 4937.5 , 4968.75, 5000.  ,\n       5031.25, 5062.5 , 5093.75, 5125.  , 5156.25, 5187.5 , 5218.75,\n       5250.  , 5281.25, 5312.5 , 5343.75, 5375.  , 5406.25, 5437.5 ,\n       5468.75, 5500.  , 5531.25, 5562.5 , 5593.75, 5625.  , 5656.25,\n       5687.5 , 5718.75, 5750.  , 5781.25, 5812.5 , 5843.75, 5875.  ,\n       5906.25, 5937.5 , 5968.75, 6000.  , 6031.25, 6062.5 , 6093.75,\n       6125.  , 6156.25, 6187.5 , 6218.75, 6250.  , 6281.25, 6312.5 ,\n       6343.75, 6375.  , 6406.25, 6437.5 , 6468.75, 6500.  , 6531.25,\n       6562.5 , 6593.75, 6625.  , 6656.25, 6687.5 , 6718.75, 6750.  ,\n       6781.25, 6812.5 , 6843.75, 6875.  , 6906.25, 6937.5 , 6968.75,\n       7000.  , 7031.25, 7062.5 , 7093.75, 7125.  , 7156.25, 7187.5 ,\n       7218.75, 7250.  , 7281.25, 7312.5 , 7343.75, 7375.  , 7406.25,\n       7437.5 , 7468.75, 7500.  , 7531.25, 7562.5 , 7593.75, 7625.  ,\n       7656.25, 7687.5 , 7718.75, 7750.  , 7781.25, 7812.5 , 7843.75,\n       7875.  , 7906.25, 7937.5 , 7968.75, 8000.  ])"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_freq"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The computed spectra is complex conjugate symmetric because the input signal is real, and one of the properties of the discrete Fourier transform is that the spectrum of a real signal is complex conjugate symmetric."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the upper half of the spectrum is redundant it can be removed, this saves memory and computation time. Moreover, given a sampling frequency, only frequencies up to the Nyquist frequency are relevant for speech signal processing.\n",
    "\n",
    "Another advantage is that considering only the non-redundant part of the spectrum makes visualization easier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "#m_stft = np.zeros((m_frames.shape[0], (int(m_frames.shape[1]/2)+1)), dtype=np.complex128)\n",
    "#m_stft.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "#m_stft[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
