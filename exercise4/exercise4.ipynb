{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sr\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-30T13:25:46.902393500Z",
     "start_time": "2023-05-30T13:25:44.409509100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#2.1)\n",
    "\n",
    "speech_data_tuple = sr.read(\"resources/female8khz.wav\")\n",
    "speech_data = speech_data_tuple[0]\n",
    "sampling_rate = speech_data_tuple[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-30T13:25:48.316796400Z",
     "start_time": "2023-05-30T13:25:48.307786900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def my_windowing(v_signal: np.ndarray, sampling_rate: int, frame_length: int, frame_shift: int) -> [np.ndarray, np.ndarray]:\n",
    "    millis_per_sample = 1000 / sampling_rate\n",
    "    frame_length_num_points = frame_length / millis_per_sample\n",
    "    frame_shift_num_points = frame_shift / millis_per_sample\n",
    "    num_frames = int(np.floor((len(v_signal) - frame_length_num_points) / frame_shift_num_points) + 1)\n",
    "    m_frames = np.zeros((num_frames, int(frame_length_num_points)))\n",
    "    v_time_frame = np.zeros(num_frames)\n",
    "    for i in range(num_frames):\n",
    "        start = int(i * frame_shift_num_points)\n",
    "        end = int(i * frame_shift_num_points + frame_length_num_points)\n",
    "        m_frames[i] = v_signal[start:end]\n",
    "        v_time_frame[i] = (start + end)/(2*sampling_rate)\n",
    "    return [m_frames, v_time_frame]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-30T13:29:02.153065200Z",
     "start_time": "2023-05-30T13:29:02.143090200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "frame_length = 32\n",
    "frame_shift = 8\n",
    "\n",
    "m_frames, v_time_frame = my_windowing(speech_data, sampling_rate, frame_length, frame_shift)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-30T13:29:05.319878Z",
     "start_time": "2023-05-30T13:29:05.314891100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(278,)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_time_frame.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-30T13:30:08.704974100Z",
     "start_time": "2023-05-30T13:30:08.682927300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.1.a) The signal is segmented because analyzing the whole signal at once might be too computationally expensive, particularly for longer audio segments. When doing convolutions both to analyze the signal in the frequency domain or apply analysis windows padding has to be done, this padding grows proportionally to the audio segment length. Therefore, it is more efficient to segment the audio signal in smaller segments."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.1.b) Typically, 32ms length segment is considered appropriate for speech signal processing. This is because it has been found to be a good compromise between having a small segment length in terms of reducing computational complexity and having a segment long enough to capture the frequency characteristics of speech signals."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_power():\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
